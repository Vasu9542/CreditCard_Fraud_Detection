# üí≥ Credit Card Fraud Detection

A machine learning project to detect fraudulent credit card transactions using **Logistic Regression**.

---

## üìå Project Overview
This project demonstrates:
- Loading and cleaning credit card transaction data
- Handling missing values
- Balancing imbalanced datasets with under-sampling
- Training a Logistic Regression model for fraud detection
- Evaluating model performance using accuracy score and visualizations

---

## üõ†Ô∏è Technologies Used
- Python
- NumPy
- Pandas
- Scikit-learn
- Matplotlib / Seaborn

---

## üìÇ Dataset
The dataset used is `creditcard.csv` containing anonymized transaction data labeled as:
- `0` ‚Äì Legitimate transaction
- `1` ‚Äì Fraudulent transaction

---

## ‚öôÔ∏è Workflow

### 1Ô∏è‚É£ Import Libraries
```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression

2Ô∏è‚É£ Load Dataset
Always show details
cc_data = pd.read_csv('creditcard.csv')

3Ô∏è‚É£ Data Cleaning

Checked for missing values

Removed rows with null values

Always show details
creditcard_data = cc_data.dropna()

4Ô∏è‚É£ Exploratory Data Analysis

Distribution of legitimate vs fraudulent transactions

Statistical comparison of transaction amounts

5Ô∏è‚É£ Handle Imbalanced Data (Under-sampling)
Always show details
legit_sample = legit.sample(n=493)
N_Dataset = pd.concat([legit_sample, fraud], axis=0)

6Ô∏è‚É£ Split Data into Training & Testing Sets
Always show details
X = N_Dataset.drop(columns='Class', axis=1)
y = N_Dataset['Class']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=2
)

7Ô∏è‚É£ Train Logistic Regression Model
Always show details
model = LogisticRegression()
model.fit(X_train, y_train)

8Ô∏è‚É£ Evaluate Model
Always show details
X_train_pred = model.predict(X_train)
train_acc = accuracy_score(y_train, X_train_pred)
X_test_pred = model.predict(X_test)
test_acc = accuracy_score(y_test, X_test_pred)
print("Training Accuracy:", train_acc)
print("Testing Accuracy:", test_acc)

üìä Visualizations
1Ô∏è‚É£ Class Distribution
Always show details
import seaborn as sns
sns.countplot(x='Class', data=creditcard_data)
plt.title('Class Distribution')
plt.show()

2Ô∏è‚É£ Transaction Amount Distribution
Always show details
legit.Amount.describe()
fraud.Amount.describe()

3Ô∏è‚É£ ROC Curve & Confusion Matrix
Always show details
from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay

y_pred_prob = model.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

cm = confusion_matrix(y_test, model.predict(X_test))
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

```
These plots visually show dataset imbalance, model performance, and classification quality.

üöÄ How to Run

Clone this repository

Place creditcard.csv in the project folder

Install dependencies:

Always show details
pip install numpy pandas scikit-learn matplotlib seaborn


Run the notebook or Python script

üìå Future Improvements

Try Random Forest or XGBoost

Use SMOTE oversampling instead of under-sampling

Add Precision, Recall, F1-score, ROC-AUC metrics

